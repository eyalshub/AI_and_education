{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Take-Home Assignment: AI Content Generation Service for LMS**\n",
        "\n",
        "**Context:**\n",
        "\n",
        "We are developing features for our Learning Management System (LMS). Content creators build lessons using various components like paragraphs, questions, and quizzes. To streamline this process, we want to add a \"Generate with AI\" button for each component type. Clicking this button will trigger a backend service that uses an LLM to generate the content based on minimal user input (e.g., a topic). The generated content, structured as JSON, will then be sent back to the frontend to populate the component.\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "Your task is to design and implement a Python backend service, suitable for deployment as a serverless function (e.g., Google Cloud Function or Cloud Run service), that fulfills this AI content generation requirement.\n",
        "\n",
        "**Part A: Core Task**\n",
        "\n",
        "Develop a Python function that:\n",
        "\n",
        "1.  Accepts an HTTP POST request with a JSON payload containing:\n",
        "    *   `topic`: A string describing the subject matter (e.g., \"Introduction to Python Variables\", \"Photosynthesis Basics\").\n",
        "    *   `content_type`: A string indicating the type of content to generate. Possible values: `\"paragraph\"`, `\"multiple_choice_question\"`, `\"quiz\"`.\n",
        "    *   `context` (Optional): An optional string providing additional context or specific instructions for the generation (e.g., \"Explain for beginners\", \"Focus on the Krebs cycle\").\n",
        "\n",
        "2.  Based on the `content_type`, interacts with the OpenAI API or Gemini API to generate the requested content.\n",
        "    *   You will need to design effective **system prompts** and potentially construct dynamic **user prompts** based on the input `topic` and `context`. Consider how to guide the LLM to produce relevant and accurate content for an educational setting.\n",
        "    *   Think about potential **meta-prompting** strategies if needed, especially for complex tasks like quiz generation.\n",
        "\n",
        "3.  You must ensure the LLM's output is parsed and returned as a **structured JSON response** (structured output). The structure should differ based on the requested `content_type`. Define and implement the following JSON output schemas:\n",
        "\n",
        "    *   **For `content_type: \"paragraph\"`:**\n",
        "        ```json\n",
        "        {\n",
        "          \"type\": \"paragraph\",\n",
        "          \"content\": \"Generated text content for the paragraph...\"\n",
        "        }\n",
        "        ```\n",
        "\n",
        "    *   **For `content_type: \"multiple_choice_question\"`:**\n",
        "        ```json\n",
        "        {\n",
        "          \"type\": \"multiple_choice_question\",\n",
        "          \"question_text\": \"The generated question?\",\n",
        "          \"options\": [\n",
        "            \"Option A\",\n",
        "            \"Option B\",\n",
        "            \"Option C\",\n",
        "            \"Option D\"\n",
        "          ],\n",
        "          \"correct_answer_index\": 2 // Index of the correct answer in the options array (0-based)\n",
        "        }\n",
        "        ```\n",
        "        *(Assume 4 options for simplicity, unless you want to make it variable)*\n",
        "\n",
        "    *   **For `content_type: \"quiz\"`:**\n",
        "        ```json\n",
        "        {\n",
        "          \"type\": \"quiz\",\n",
        "          \"title\": \"Quiz Title related to the topic\",\n",
        "          \"questions\": [\n",
        "            // An array of multiple_choice_question objects (use the schema above)\n",
        "            // Aim for 3-5 questions per quiz for this assignment\n",
        "            {\n",
        "              \"type\": \"multiple_choice_question\",\n",
        "              \"question_text\": \"Question 1?\",\n",
        "              \"options\": [\"A\", \"B\", \"C\", \"D\"],\n",
        "              \"correct_answer_index\": 0\n",
        "            },\n",
        "            {\n",
        "              \"type\": \"multiple_choice_question\",\n",
        "              \"question_text\": \"Question 2?\",\n",
        "              \"options\": [\"A\", \"B\", \"C\", \"D\"],\n",
        "              \"correct_answer_index\": 3\n",
        "            }\n",
        "            // ... more questions\n",
        "          ]\n",
        "        }\n",
        "        ```\n",
        "\n",
        "4.  Handles basic error scenarios (e.g., invalid input, failure from the LLM API).\n",
        "\n",
        "**Technical Requirements:**\n",
        "\n",
        "*   **Language:** Python.\n",
        "*   **LLM:** Use the OpenAI API (or Gemini API, which is free through Google AI Studio). You can use your own API key for development (mention this in your setup instructions).\n",
        "*   **API Key Management:** Do not hardcode the API key. Assume it will be provided via an environment variable  (like using .env).\n",
        "*   **Serverless Structure:** Structure your code so it can be easily deployed as a Google Cloud Function (HTTP Trigger) or a simple container for Cloud Run. You don't need to actually deploy it, but the entry point and dependencies should be clear. Using a lightweight web framework like FastAPI is acceptable and often helpful.\n",
        "*   **Dependencies:** Clearly list all dependencies (e.g., in a `requirements.txt` file).\n",
        "*   **Logging:** Implementing robust error handling and logging.\n",
        "\n",
        "**Bonus Points (Optional):**\n",
        "\n",
        "*   Demonstrating advanced prompt engineering techniques (e.g., few-shot examples, chain-of-thought prompting if applicable).\n",
        "*   Handling variability (e.g., allowing the user to specify the number of quiz questions or multiple-choice options).\n",
        "*   Adding input validation.\n",
        "\n",
        "---\n",
        "\n",
        "**Part B: High-Level System Design â€“ Generating Full Lessons and Courses with AI**\n",
        "\n",
        "**Context:**  \n",
        "The backend service you implemented in Part A is just one building block in a larger vision: enabling content creators to generate entire lessons, and even full courses (a sequence of lessons), using AI within the LMS.\n",
        "\n",
        "**Your Task:**  \n",
        "Describe, at a high level, how you would design the end-to-end pipeline for generating a full lesson and a full course using LLMs. Your answer should demonstrate your system thinking, architectural skills, and awareness of integration, security, and cloud infrastructure.\n",
        "\n",
        "**Please address the following:**\n",
        "\n",
        "1. **High-Level Diagram:**  \n",
        "   Present a high-level architecture diagram (you may use a drawing tool, draw by hand and scan, or describe textually). The diagram should show the main components and data flow for generating a full lesson and a full course using LLMs within the LMS.\n",
        "\n",
        "2. **Where does the LLM fit in?**  \n",
        "   Explain at which stages the LLM is used in the process (e.g., generating lesson outlines, lesson content, quizzes, etc.).\n",
        "\n",
        "3. **Database Choice:**  \n",
        "   Which database(s) would you use to store generated content and metadata? Briefly justify your choice.\n",
        "\n",
        "4. **LMS Team Collaboration:**  \n",
        "   What do you need from the LMS team to successfully integrate your pipeline? (e.g., APIs, data models, permissions, etc.)\n",
        "\n",
        "5. **Cloud Infrastructure (GCP):**  \n",
        "   What are the key cloud resources and services you would use in Google Cloud Platform to support this pipeline? (e.g., Cloud Functions, Cloud Run, Firestore, Secret Manager, etc.)\n",
        "\n",
        "6. **Security Principles:**  \n",
        "   List and briefly explain the main security principles and practices you would enforce in your solution.\n",
        "\n",
        "7. **(Optional) Additional Considerations:**  \n",
        "   If you have further architectural considerations, tradeoffs, or ideas (e.g., scalability, cost, monitoring), feel free to add them.\n",
        "\n",
        "**Deliverable:**  \n",
        "Add your answer to Part B as a separate section in your repository (in the README or as a separate file), including the diagram and explanations.\n",
        "\n",
        "---\n",
        "\n",
        "**Deliverables:**\n",
        "\n",
        "1.  A link to a GitHub repository containing your source code.\n",
        "2.  A `README.md` file in the repository that includes:\n",
        "    *   Clear instructions on how to set up the environment and run the code locally (including setting the API key).\n",
        "    *   Examples of how to call your function (e.g., using `curl` or Python's `requests`).\n",
        "    *   A brief explanation of your design choices, especially regarding prompt engineering and ensuring structured output.\n",
        "    *   Examples of the prompts you designed for each `content_type`.\n",
        "    *   Any assumptions made or limitations of your solution.\n",
        "    *   **Your answer to Part B (system design).**\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "\n",
        "*   **Functionality:** Does the service correctly generate content for each type based on the input?\n",
        "*   **Structured Output:** Does the output strictly adhere to the specified JSON schemas?\n",
        "*   **Code Quality:** Is the Python code clean, well-organized, readable, and maintainable?\n",
        "*   **Prompt Engineering:** How effective are the prompts in generating relevant, accurate, and appropriately structured content?\n",
        "*   **Error Handling:** Does the service handle basic errors gracefully?\n",
        "*   **Documentation:** Is the `README.md` clear and comprehensive?\n",
        "*   **Serverless Suitability:** Is the code structured appropriately for serverless deployment?\n",
        "*   **System Design:** Is the architecture in Part B logical, secure, and cloud-ready?\n",
        "\n",
        "**Timeframe:**\n",
        "\n",
        "Please aim to complete this assignment until 08/05/2025. Let me know if you foresee any issues with this timeframe.\n",
        "\n",
        "**Questions:**\n",
        "\n",
        "If you have any questions about the assignment, please don't hesitate to reach out to me.\n",
        "\n",
        "Good luck! I look forward to seeing your solution.\n",
        "\n",
        "\n",
        "Yedidya Harris @ Reshet Amit"
      ],
      "metadata": {
        "id": "p6hknR7ZBIvm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vjihIQbwblCa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}